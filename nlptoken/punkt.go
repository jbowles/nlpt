package nlptoken

/*
// Implement the Punkt algorithm

// Natural Language Toolkit: Punkt sentence tokenizer
//
// Copyright (C) 2001-2013 NLTK Project
// Algorithm: Kiss & Strunk (2006)
// Author: Willy <willy@csse.unimelb.edu.au> (original Python port)
//         Steven Bird <stevenbird1@gmail.com> (additions)
//         Edward Loper <edloper@gradient.cis.upenn.edu> (rewrite)
//         Joel Nothman <jnothman@student.usyd.edu.au> (almost rewrite)
// URL: <http://www.nltk.org/>

// Kiss, Strunk, Jan (2006): Unsupervised Multilingual Sentence Boundary Detection.
// Computational Linguistics 32: 485-525.

Implementations I have borrowed from:

// [Original Python Implementation](https://github.com/nltk/nltk/blob/master/nltk/tokenize/punkt.py)
// [Ruby Punkt Segmenter](https://github.com/lfcipriani/punkt-segmenter)
// [Ruby Punkt in TREAT](https://github.com/louismullie/treat/blob/master/lib/treat/workers/processors/tokenizers/punkt.rb)
*/
