// Copyright Â©2013 The rivet Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.
package nlptoken

/*
// Implement the Punkt algorithm in Go

// Natural Language Toolkit: Punkt sentence tokenizer
//
// Copyright (C) 2001-2013 NLTK Project
// Algorithm: Kiss & Strunk (2006)
// Author: Willy <willy@csse.unimelb.edu.au> (original Python port)
//         Steven Bird <stevenbird1@gmail.com> (additions)
//         Edward Loper <edloper@gradient.cis.upenn.edu> (rewrite)
//         Joel Nothman <jnothman@student.usyd.edu.au> (almost rewrite)
// URL: <http://www.nltk.org/>

// Kiss, Strunk, Jan (2006): Unsupervised Multilingual Sentence Boundary Detection.
// Computational Linguistics 32: 485-525.

Implementations I have borrowed from:

// [Original Python Implementation](https://github.com/nltk/nltk/blob/master/nltk/tokenize/punkt.py)
// [Ruby Punkt Segmenter](https://github.com/lfcipriani/punkt-segmenter)
// [Ruby Punkt in TREAT](https://github.com/louismullie/treat/blob/master/lib/treat/workers/processors/tokenizers/punkt.rb)
*/
